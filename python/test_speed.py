#!/usr/bin/env python3
"""
Script de teste para comparar velocidade dos modelos Whisper
"""

import time
import whisper
import torch

def test_model_speed(model_name: str, test_audio_path: str = "test_audio.wav"):
    """Testa a velocidade de um modelo Whisper"""
    print(f"\nğŸ§ª Testando modelo: {model_name}")
    
    # Carregar modelo
    start_time = time.time()
    model = whisper.load_model(model_name, device="cpu")
    load_time = time.time() - start_time
    print(f"â±ï¸  Tempo de carregamento: {load_time:.2f}s")
    
    # Configurar PyTorch para mÃ¡xima performance
    torch.set_num_threads(8)
    torch.set_default_dtype(torch.float32)
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    torch.set_grad_enabled(False)
    
    # Teste de transcriÃ§Ã£o (se arquivo existir)
    try:
        start_time = time.time()
        result = model.transcribe(
            test_audio_path,
            beam_size=2,
            best_of=1,
            temperature=0.0,
            patience=1,
            length_penalty=1.0,
            word_timestamps=True,
            condition_on_previous_text=False,
            language="pt"
        )
        transcribe_time = time.time() - start_time
        print(f"âš¡ Tempo de transcriÃ§Ã£o: {transcribe_time:.2f}s")
        print(f"ğŸ“ Texto gerado: {result['text'][:100]}...")
        return transcribe_time
    except FileNotFoundError:
        print(f"âš ï¸  Arquivo {test_audio_path} nÃ£o encontrado, pulando teste de transcriÃ§Ã£o")
        return None

def main():
    print("ğŸš€ Teste de Velocidade - Modelos Whisper")
    print("=" * 50)
    
    # Testar modelos
    models = ["tiny", "base", "small", "medium"]
    results = {}
    
    for model in models:
        transcribe_time = test_model_speed(model)
        if transcribe_time:
            results[model] = transcribe_time
    
    # ComparaÃ§Ã£o
    if results:
        print("\nğŸ“Š ComparaÃ§Ã£o de Velocidade:")
        print("-" * 30)
        
        fastest_model = min(results, key=results.get)
        fastest_time = results[fastest_model]
        
        for model, time_taken in results.items():
            speed_factor = fastest_time / time_taken
            print(f"{model:6} | {time_taken:6.2f}s | {speed_factor:5.1f}x {'ğŸš€' if model == fastest_model else ''}")
        
        print(f"\nğŸ¯ RecomendaÃ§Ã£o: Use o modelo '{fastest_model}' para mÃ¡xima velocidade!")

if __name__ == "__main__":
    main() 